{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [0], Loss: 0.11465086042881012\n",
      "Epoch [1/10], Batch [10], Loss: 0.05471189320087433\n",
      "Epoch [1/10], Batch [20], Loss: 0.03394618630409241\n",
      "Epoch [1/10], Batch [30], Loss: 0.018991105258464813\n",
      "Epoch [1/10], Batch [40], Loss: 0.020804837346076965\n",
      "Epoch [1/10], Batch [50], Loss: 0.02055756375193596\n",
      "Epoch [1/10], Batch [60], Loss: 0.020110368728637695\n",
      "Epoch [1/10], Batch [70], Loss: 0.0274219773709774\n",
      "Epoch [1/10], Batch [80], Loss: 0.04723837599158287\n",
      "Epoch [1/10], Batch [90], Loss: 0.0172162763774395\n",
      "Epoch [1/10], Batch [100], Loss: 0.0169746782630682\n",
      "Epoch [1/10], Batch [110], Loss: 0.024242322891950607\n",
      "Epoch [1/10], Batch [120], Loss: 0.009426560252904892\n",
      "Epoch [1/10], Batch [130], Loss: 0.028283651918172836\n",
      "Epoch [1/10], Batch [140], Loss: 0.018449250608682632\n",
      "Epoch [1/10], Batch [150], Loss: 0.06661301851272583\n",
      "Epoch [1/10], Batch [160], Loss: 0.02990836463868618\n",
      "Epoch [1/10], Batch [170], Loss: 0.024279845878481865\n",
      "Epoch [1/10], Batch [180], Loss: 0.021444251760840416\n",
      "Epoch [1/10], Batch [190], Loss: 0.025021344423294067\n",
      "Epoch [1/10], Batch [200], Loss: 0.02338160201907158\n",
      "Epoch [1/10], Batch [210], Loss: 0.018076900392770767\n",
      "Epoch [1/10], Batch [220], Loss: 0.01020754873752594\n",
      "Epoch [1/10], Batch [230], Loss: 0.010288381017744541\n",
      "Epoch [1/10], Batch [240], Loss: 0.01209358498454094\n",
      "Epoch [1/10], Batch [250], Loss: 0.008175872266292572\n",
      "Epoch [1/10], Batch [260], Loss: 0.039658308029174805\n",
      "Epoch [1/10], Batch [270], Loss: 0.01562205795198679\n",
      "Epoch [1/10], Batch [280], Loss: 0.019403602927923203\n",
      "Epoch [1/10], Batch [290], Loss: 0.026493001729249954\n",
      "Epoch [1/10], Batch [300], Loss: 0.01354697160422802\n",
      "Epoch [1/10], Batch [310], Loss: 0.014256598427891731\n",
      "Epoch [1/10], Batch [320], Loss: 0.024545462802052498\n",
      "Epoch [1/10], Batch [330], Loss: 0.017313258722424507\n",
      "Epoch [1/10], Batch [340], Loss: 0.013624286279082298\n",
      "Epoch [1/10], Batch [350], Loss: 0.0127589525654912\n",
      "Epoch [1/10], Batch [360], Loss: 0.019456613808870316\n",
      "Epoch [1/10], Batch [370], Loss: 0.006966003216803074\n",
      "Epoch [1/10], Batch [380], Loss: 0.03865186497569084\n",
      "Epoch [1/10], Batch [390], Loss: 0.03588593751192093\n",
      "Epoch [1/10], Batch [400], Loss: 0.011979917995631695\n",
      "Epoch [1/10], Batch [410], Loss: 0.07435678690671921\n",
      "Epoch [1/10], Batch [420], Loss: 0.05013585463166237\n",
      "Epoch [1/10], Batch [430], Loss: 0.04350601136684418\n",
      "Epoch [1/10], Batch [440], Loss: 0.03297732025384903\n",
      "Epoch [1/10], Batch [450], Loss: 0.027091218158602715\n",
      "Epoch [1/10], Batch [460], Loss: 0.02749505080282688\n",
      "Epoch [1/10], Batch [470], Loss: 0.0252834465354681\n",
      "Epoch [1/10], Batch [480], Loss: 0.0339784100651741\n",
      "Epoch [1/10], Batch [490], Loss: 0.030388984829187393\n",
      "Epoch [1/10], Batch [500], Loss: 0.020382918417453766\n",
      "Epoch [1/10], Batch [510], Loss: 0.024861222133040428\n",
      "Epoch [1/10], Batch [520], Loss: 0.021151328459382057\n",
      "Epoch [1/10], Batch [530], Loss: 0.029069336131215096\n",
      "Epoch [1/10], Batch [540], Loss: 0.0273568257689476\n",
      "Epoch [1/10], Batch [550], Loss: 0.01676998659968376\n",
      "Epoch [1/10], Average Loss: 0.03130634564237557\n",
      "Epoch [2/10], Batch [0], Loss: 0.05393951013684273\n",
      "Epoch [2/10], Batch [10], Loss: 0.03702723979949951\n",
      "Epoch [2/10], Batch [20], Loss: 0.011639484204351902\n",
      "Epoch [2/10], Batch [30], Loss: 0.010808004066348076\n",
      "Epoch [2/10], Batch [40], Loss: 0.012642193585634232\n",
      "Epoch [2/10], Batch [50], Loss: 0.012462903745472431\n",
      "Epoch [2/10], Batch [60], Loss: 0.010077259503304958\n",
      "Epoch [2/10], Batch [70], Loss: 0.01870141737163067\n",
      "Epoch [2/10], Batch [80], Loss: 0.044578906148672104\n",
      "Epoch [2/10], Batch [90], Loss: 0.013519452884793282\n",
      "Epoch [2/10], Batch [100], Loss: 0.014406718313694\n",
      "Epoch [2/10], Batch [110], Loss: 0.022937359288334846\n",
      "Epoch [2/10], Batch [120], Loss: 0.008360475301742554\n",
      "Epoch [2/10], Batch [130], Loss: 0.0067907036282122135\n",
      "Epoch [2/10], Batch [140], Loss: 0.015318009071052074\n",
      "Epoch [2/10], Batch [150], Loss: 0.040581535547971725\n",
      "Epoch [2/10], Batch [160], Loss: 0.02508566342294216\n",
      "Epoch [2/10], Batch [170], Loss: 0.019262392073869705\n",
      "Epoch [2/10], Batch [180], Loss: 0.02120780758559704\n",
      "Epoch [2/10], Batch [190], Loss: 0.024551205337047577\n",
      "Epoch [2/10], Batch [200], Loss: 0.02301410771906376\n",
      "Epoch [2/10], Batch [210], Loss: 0.01772594265639782\n",
      "Epoch [2/10], Batch [220], Loss: 0.009813372045755386\n",
      "Epoch [2/10], Batch [230], Loss: 0.009737111628055573\n",
      "Epoch [2/10], Batch [240], Loss: 0.00500123854726553\n",
      "Epoch [2/10], Batch [250], Loss: 0.006995459087193012\n",
      "Epoch [2/10], Batch [260], Loss: 0.03824331611394882\n",
      "Epoch [2/10], Batch [270], Loss: 0.013692611828446388\n",
      "Epoch [2/10], Batch [280], Loss: 0.017565736547112465\n",
      "Epoch [2/10], Batch [290], Loss: 0.024854913353919983\n",
      "Epoch [2/10], Batch [300], Loss: 0.012261200696229935\n",
      "Epoch [2/10], Batch [310], Loss: 0.01323245745152235\n",
      "Epoch [2/10], Batch [320], Loss: 0.023033853620290756\n",
      "Epoch [2/10], Batch [330], Loss: 0.01535792276263237\n",
      "Epoch [2/10], Batch [340], Loss: 0.014153941534459591\n",
      "Epoch [2/10], Batch [350], Loss: 0.012319422326982021\n",
      "Epoch [2/10], Batch [360], Loss: 0.01853211782872677\n",
      "Epoch [2/10], Batch [370], Loss: 0.006356995087116957\n",
      "Epoch [2/10], Batch [380], Loss: 0.037904806435108185\n",
      "Epoch [2/10], Batch [390], Loss: 0.034970302134752274\n",
      "Epoch [2/10], Batch [400], Loss: 0.011691819876432419\n",
      "Epoch [2/10], Batch [410], Loss: 0.021063951775431633\n",
      "Epoch [2/10], Batch [420], Loss: 0.02266567200422287\n",
      "Epoch [2/10], Batch [430], Loss: 0.018801311030983925\n",
      "Epoch [2/10], Batch [440], Loss: 0.020849043503403664\n",
      "Epoch [2/10], Batch [450], Loss: 0.020850323140621185\n",
      "Epoch [2/10], Batch [460], Loss: 0.01620318554341793\n",
      "Epoch [2/10], Batch [470], Loss: 0.013764342293143272\n",
      "Epoch [2/10], Batch [480], Loss: 0.011173171922564507\n",
      "Epoch [2/10], Batch [490], Loss: 0.016498230397701263\n",
      "Epoch [2/10], Batch [500], Loss: 0.01656355708837509\n",
      "Epoch [2/10], Batch [510], Loss: 0.01142075750976801\n",
      "Epoch [2/10], Batch [520], Loss: 0.011755007319152355\n",
      "Epoch [2/10], Batch [530], Loss: 0.026725521311163902\n",
      "Epoch [2/10], Batch [540], Loss: 0.020542992278933525\n",
      "Epoch [2/10], Batch [550], Loss: 0.012880819849669933\n",
      "Epoch [2/10], Average Loss: 0.022529901567350664\n",
      "Epoch [3/10], Batch [0], Loss: 0.02397630177438259\n",
      "Epoch [3/10], Batch [10], Loss: 0.03294662758708\n",
      "Epoch [3/10], Batch [20], Loss: 0.010141890496015549\n",
      "Epoch [3/10], Batch [30], Loss: 0.010126187466084957\n",
      "Epoch [3/10], Batch [40], Loss: 0.011820555664598942\n",
      "Epoch [3/10], Batch [50], Loss: 0.011599104851484299\n",
      "Epoch [3/10], Batch [60], Loss: 0.009580929763615131\n",
      "Epoch [3/10], Batch [70], Loss: 0.01749677211046219\n",
      "Epoch [3/10], Batch [80], Loss: 0.04419752210378647\n",
      "Epoch [3/10], Batch [90], Loss: 0.013101461343467236\n",
      "Epoch [3/10], Batch [100], Loss: 0.013257316313683987\n",
      "Epoch [3/10], Batch [110], Loss: 0.022146116942167282\n",
      "Epoch [3/10], Batch [120], Loss: 0.007489932235330343\n",
      "Epoch [3/10], Batch [130], Loss: 0.006654893513768911\n",
      "Epoch [3/10], Batch [140], Loss: 0.014329172670841217\n",
      "Epoch [3/10], Batch [150], Loss: 0.03889290243387222\n",
      "Epoch [3/10], Batch [160], Loss: 0.02442963421344757\n",
      "Epoch [3/10], Batch [170], Loss: 0.017843378707766533\n",
      "Epoch [3/10], Batch [180], Loss: 0.019698336720466614\n",
      "Epoch [3/10], Batch [190], Loss: 0.023062974214553833\n",
      "Epoch [3/10], Batch [200], Loss: 0.023027891293168068\n",
      "Epoch [3/10], Batch [210], Loss: 0.01762120984494686\n",
      "Epoch [3/10], Batch [220], Loss: 0.009684297256171703\n",
      "Epoch [3/10], Batch [230], Loss: 0.009435513988137245\n",
      "Epoch [3/10], Batch [240], Loss: 0.0052194599993526936\n",
      "Epoch [3/10], Batch [250], Loss: 0.0068510654382407665\n",
      "Epoch [3/10], Batch [260], Loss: 0.03784145414829254\n",
      "Epoch [3/10], Batch [270], Loss: 0.012250561267137527\n",
      "Epoch [3/10], Batch [280], Loss: 0.01608310081064701\n",
      "Epoch [3/10], Batch [290], Loss: 0.024013090878725052\n",
      "Epoch [3/10], Batch [300], Loss: 0.011808454059064388\n",
      "Epoch [3/10], Batch [310], Loss: 0.012794021517038345\n",
      "Epoch [3/10], Batch [320], Loss: 0.02178202010691166\n",
      "Epoch [3/10], Batch [330], Loss: 0.014837265945971012\n",
      "Epoch [3/10], Batch [340], Loss: 0.013773753307759762\n",
      "Epoch [3/10], Batch [350], Loss: 0.012424074113368988\n",
      "Epoch [3/10], Batch [360], Loss: 0.01866166479885578\n",
      "Epoch [3/10], Batch [370], Loss: 0.006221876945346594\n",
      "Epoch [3/10], Batch [380], Loss: 0.03775712847709656\n",
      "Epoch [3/10], Batch [390], Loss: 0.03428955376148224\n",
      "Epoch [3/10], Batch [400], Loss: 0.0115658612921834\n",
      "Epoch [3/10], Batch [410], Loss: 0.013571104034781456\n",
      "Epoch [3/10], Batch [420], Loss: 0.01575096882879734\n",
      "Epoch [3/10], Batch [430], Loss: 0.007585992105305195\n",
      "Epoch [3/10], Batch [440], Loss: 0.016310328617691994\n",
      "Epoch [3/10], Batch [450], Loss: 0.016483617946505547\n",
      "Epoch [3/10], Batch [460], Loss: 0.015006212517619133\n",
      "Epoch [3/10], Batch [470], Loss: 0.01317032240331173\n",
      "Epoch [3/10], Batch [480], Loss: 0.007692210841923952\n",
      "Epoch [3/10], Batch [490], Loss: 0.014954134821891785\n",
      "Epoch [3/10], Batch [500], Loss: 0.01351169589906931\n",
      "Epoch [3/10], Batch [510], Loss: 0.009807209484279156\n",
      "Epoch [3/10], Batch [520], Loss: 0.009863548912107944\n",
      "Epoch [3/10], Batch [530], Loss: 0.025472506880760193\n",
      "Epoch [3/10], Batch [540], Loss: 0.01830756850540638\n",
      "Epoch [3/10], Batch [550], Loss: 0.010157949291169643\n",
      "Epoch [3/10], Average Loss: 0.02057215644195634\n",
      "Epoch [4/10], Batch [0], Loss: 0.021454550325870514\n",
      "Epoch [4/10], Batch [10], Loss: 0.029503386467695236\n",
      "Epoch [4/10], Batch [20], Loss: 0.010082357563078403\n",
      "Epoch [4/10], Batch [30], Loss: 0.009856055490672588\n",
      "Epoch [4/10], Batch [40], Loss: 0.008038542233407497\n",
      "Epoch [4/10], Batch [50], Loss: 0.011304390616714954\n",
      "Epoch [4/10], Batch [60], Loss: 0.007619817741215229\n",
      "Epoch [4/10], Batch [70], Loss: 0.016544653102755547\n",
      "Epoch [4/10], Batch [80], Loss: 0.044016771018505096\n",
      "Epoch [4/10], Batch [90], Loss: 0.012278386391699314\n",
      "Epoch [4/10], Batch [100], Loss: 0.01224270649254322\n",
      "Epoch [4/10], Batch [110], Loss: 0.021484985947608948\n",
      "Epoch [4/10], Batch [120], Loss: 0.006531123071908951\n",
      "Epoch [4/10], Batch [130], Loss: 0.00708752078935504\n",
      "Epoch [4/10], Batch [140], Loss: 0.013756447471678257\n",
      "Epoch [4/10], Batch [150], Loss: 0.038165148347616196\n",
      "Epoch [4/10], Batch [160], Loss: 0.023649442940950394\n",
      "Epoch [4/10], Batch [170], Loss: 0.017250845208764076\n",
      "Epoch [4/10], Batch [180], Loss: 0.01912909932434559\n",
      "Epoch [4/10], Batch [190], Loss: 0.022802606225013733\n",
      "Epoch [4/10], Batch [200], Loss: 0.023099932819604874\n",
      "Epoch [4/10], Batch [210], Loss: 0.01762978918850422\n",
      "Epoch [4/10], Batch [220], Loss: 0.00962524488568306\n",
      "Epoch [4/10], Batch [230], Loss: 0.00928809680044651\n",
      "Epoch [4/10], Batch [240], Loss: 0.00507019367069006\n",
      "Epoch [4/10], Batch [250], Loss: 0.006734502501785755\n",
      "Epoch [4/10], Batch [260], Loss: 0.03765152394771576\n",
      "Epoch [4/10], Batch [270], Loss: 0.011513491161167622\n",
      "Epoch [4/10], Batch [280], Loss: 0.015332533046603203\n",
      "Epoch [4/10], Batch [290], Loss: 0.023662414401769638\n",
      "Epoch [4/10], Batch [300], Loss: 0.0114293172955513\n",
      "Epoch [4/10], Batch [310], Loss: 0.012458939105272293\n",
      "Epoch [4/10], Batch [320], Loss: 0.021153388544917107\n",
      "Epoch [4/10], Batch [330], Loss: 0.014298402704298496\n",
      "Epoch [4/10], Batch [340], Loss: 0.01339675672352314\n",
      "Epoch [4/10], Batch [350], Loss: 0.01267352607101202\n",
      "Epoch [4/10], Batch [360], Loss: 0.018870750442147255\n",
      "Epoch [4/10], Batch [370], Loss: 0.0060106972232460976\n",
      "Epoch [4/10], Batch [380], Loss: 0.0377020500600338\n",
      "Epoch [4/10], Batch [390], Loss: 0.033665455877780914\n",
      "Epoch [4/10], Batch [400], Loss: 0.011897577904164791\n",
      "Epoch [4/10], Batch [410], Loss: 0.011760243214666843\n",
      "Epoch [4/10], Batch [420], Loss: 0.01698368601500988\n",
      "Epoch [4/10], Batch [430], Loss: 0.0064728460274636745\n",
      "Epoch [4/10], Batch [440], Loss: 0.015718763694167137\n",
      "Epoch [4/10], Batch [450], Loss: 0.01484211627393961\n",
      "Epoch [4/10], Batch [460], Loss: 0.012028457596898079\n",
      "Epoch [4/10], Batch [470], Loss: 0.012134719640016556\n",
      "Epoch [4/10], Batch [480], Loss: 0.006463506259024143\n",
      "Epoch [4/10], Batch [490], Loss: 0.014441350474953651\n",
      "Epoch [4/10], Batch [500], Loss: 0.012685569934546947\n",
      "Epoch [4/10], Batch [510], Loss: 0.00988725759088993\n",
      "Epoch [4/10], Batch [520], Loss: 0.00991932861506939\n",
      "Epoch [4/10], Batch [530], Loss: 0.024225417524576187\n",
      "Epoch [4/10], Batch [540], Loss: 0.017520276829600334\n",
      "Epoch [4/10], Batch [550], Loss: 0.009612979367375374\n",
      "Epoch [4/10], Average Loss: 0.019720212742373747\n",
      "Epoch [5/10], Batch [0], Loss: 0.020456528291106224\n",
      "Epoch [5/10], Batch [10], Loss: 0.026631547138094902\n",
      "Epoch [5/10], Batch [20], Loss: 0.009270966984331608\n",
      "Epoch [5/10], Batch [30], Loss: 0.009192360565066338\n",
      "Epoch [5/10], Batch [40], Loss: 0.0052811335772275925\n",
      "Epoch [5/10], Batch [50], Loss: 0.011074277572333813\n",
      "Epoch [5/10], Batch [60], Loss: 0.006589628290385008\n",
      "Epoch [5/10], Batch [70], Loss: 0.015896614640951157\n",
      "Epoch [5/10], Batch [80], Loss: 0.04330740496516228\n",
      "Epoch [5/10], Batch [90], Loss: 0.011614161543548107\n",
      "Epoch [5/10], Batch [100], Loss: 0.01159812044352293\n",
      "Epoch [5/10], Batch [110], Loss: 0.021000543609261513\n",
      "Epoch [5/10], Batch [120], Loss: 0.005668012425303459\n",
      "Epoch [5/10], Batch [130], Loss: 0.006965878885239363\n",
      "Epoch [5/10], Batch [140], Loss: 0.013232381083071232\n",
      "Epoch [5/10], Batch [150], Loss: 0.03696140646934509\n",
      "Epoch [5/10], Batch [160], Loss: 0.0228634811937809\n",
      "Epoch [5/10], Batch [170], Loss: 0.016885247081518173\n",
      "Epoch [5/10], Batch [180], Loss: 0.018874656409025192\n",
      "Epoch [5/10], Batch [190], Loss: 0.02249394729733467\n",
      "Epoch [5/10], Batch [200], Loss: 0.02301768586039543\n",
      "Epoch [5/10], Batch [210], Loss: 0.017697801813483238\n",
      "Epoch [5/10], Batch [220], Loss: 0.009510132484138012\n",
      "Epoch [5/10], Batch [230], Loss: 0.00915917195379734\n",
      "Epoch [5/10], Batch [240], Loss: 0.005090458318591118\n",
      "Epoch [5/10], Batch [250], Loss: 0.006678458768874407\n",
      "Epoch [5/10], Batch [260], Loss: 0.037218909710645676\n",
      "Epoch [5/10], Batch [270], Loss: 0.01122669130563736\n",
      "Epoch [5/10], Batch [280], Loss: 0.014744948595762253\n",
      "Epoch [5/10], Batch [290], Loss: 0.023269398137927055\n",
      "Epoch [5/10], Batch [300], Loss: 0.01101924479007721\n",
      "Epoch [5/10], Batch [310], Loss: 0.012234997935593128\n",
      "Epoch [5/10], Batch [320], Loss: 0.020230473950505257\n",
      "Epoch [5/10], Batch [330], Loss: 0.014270768500864506\n",
      "Epoch [5/10], Batch [340], Loss: 0.013232722878456116\n",
      "Epoch [5/10], Batch [350], Loss: 0.012804919853806496\n",
      "Epoch [5/10], Batch [360], Loss: 0.018952779471874237\n",
      "Epoch [5/10], Batch [370], Loss: 0.005918508395552635\n",
      "Epoch [5/10], Batch [380], Loss: 0.03764845058321953\n",
      "Epoch [5/10], Batch [390], Loss: 0.03312276676297188\n",
      "Epoch [5/10], Batch [400], Loss: 0.012177464552223682\n",
      "Epoch [5/10], Batch [410], Loss: 0.009823346510529518\n",
      "Epoch [5/10], Batch [420], Loss: 0.01659969426691532\n",
      "Epoch [5/10], Batch [430], Loss: 0.005858602933585644\n",
      "Epoch [5/10], Batch [440], Loss: 0.015208807773888111\n",
      "Epoch [5/10], Batch [450], Loss: 0.013365461491048336\n",
      "Epoch [5/10], Batch [460], Loss: 0.011014967225492\n",
      "Epoch [5/10], Batch [470], Loss: 0.012614071369171143\n",
      "Epoch [5/10], Batch [480], Loss: 0.006307524163275957\n",
      "Epoch [5/10], Batch [490], Loss: 0.013763012364506721\n",
      "Epoch [5/10], Batch [500], Loss: 0.011701461859047413\n",
      "Epoch [5/10], Batch [510], Loss: 0.009853459894657135\n",
      "Epoch [5/10], Batch [520], Loss: 0.00910130050033331\n",
      "Epoch [5/10], Batch [530], Loss: 0.02330578677356243\n",
      "Epoch [5/10], Batch [540], Loss: 0.01664848066866398\n",
      "Epoch [5/10], Batch [550], Loss: 0.009131188504397869\n",
      "Epoch [5/10], Average Loss: 0.019104437822615623\n",
      "Epoch [6/10], Batch [0], Loss: 0.01965969055891037\n",
      "Epoch [6/10], Batch [10], Loss: 0.024891342967748642\n",
      "Epoch [6/10], Batch [20], Loss: 0.007574188057333231\n",
      "Epoch [6/10], Batch [30], Loss: 0.00886558834463358\n",
      "Epoch [6/10], Batch [40], Loss: 0.0046743410639464855\n",
      "Epoch [6/10], Batch [50], Loss: 0.011112699285149574\n",
      "Epoch [6/10], Batch [60], Loss: 0.0059866285882890224\n",
      "Epoch [6/10], Batch [70], Loss: 0.016361868008971214\n",
      "Epoch [6/10], Batch [80], Loss: 0.042901042848825455\n",
      "Epoch [6/10], Batch [90], Loss: 0.010853832587599754\n",
      "Epoch [6/10], Batch [100], Loss: 0.011313747614622116\n",
      "Epoch [6/10], Batch [110], Loss: 0.020797019824385643\n",
      "Epoch [6/10], Batch [120], Loss: 0.005116511136293411\n",
      "Epoch [6/10], Batch [130], Loss: 0.0071958256885409355\n",
      "Epoch [6/10], Batch [140], Loss: 0.012739154510200024\n",
      "Epoch [6/10], Batch [150], Loss: 0.03600029647350311\n",
      "Epoch [6/10], Batch [160], Loss: 0.021379387006163597\n",
      "Epoch [6/10], Batch [170], Loss: 0.016930613666772842\n",
      "Epoch [6/10], Batch [180], Loss: 0.01866336539387703\n",
      "Epoch [6/10], Batch [190], Loss: 0.02258126810193062\n",
      "Epoch [6/10], Batch [200], Loss: 0.02306821011006832\n",
      "Epoch [6/10], Batch [210], Loss: 0.01770445704460144\n",
      "Epoch [6/10], Batch [220], Loss: 0.009453565813601017\n",
      "Epoch [6/10], Batch [230], Loss: 0.009077819064259529\n",
      "Epoch [6/10], Batch [240], Loss: 0.004709162749350071\n",
      "Epoch [6/10], Batch [250], Loss: 0.006458221469074488\n",
      "Epoch [6/10], Batch [260], Loss: 0.03719057887792587\n",
      "Epoch [6/10], Batch [270], Loss: 0.010900286957621574\n",
      "Epoch [6/10], Batch [280], Loss: 0.01454524602741003\n",
      "Epoch [6/10], Batch [290], Loss: 0.023175276815891266\n",
      "Epoch [6/10], Batch [300], Loss: 0.011245259083807468\n",
      "Epoch [6/10], Batch [310], Loss: 0.012035876512527466\n",
      "Epoch [6/10], Batch [320], Loss: 0.019730862230062485\n",
      "Epoch [6/10], Batch [330], Loss: 0.014190544374287128\n",
      "Epoch [6/10], Batch [340], Loss: 0.013106297701597214\n",
      "Epoch [6/10], Batch [350], Loss: 0.013106108643114567\n",
      "Epoch [6/10], Batch [360], Loss: 0.01902809366583824\n",
      "Epoch [6/10], Batch [370], Loss: 0.005602700635790825\n",
      "Epoch [6/10], Batch [380], Loss: 0.03738434240221977\n",
      "Epoch [6/10], Batch [390], Loss: 0.03238704800605774\n",
      "Epoch [6/10], Batch [400], Loss: 0.012175038456916809\n",
      "Epoch [6/10], Batch [410], Loss: 0.009826941415667534\n",
      "Epoch [6/10], Batch [420], Loss: 0.016935724765062332\n",
      "Epoch [6/10], Batch [430], Loss: 0.00607523275539279\n",
      "Epoch [6/10], Batch [440], Loss: 0.014851287938654423\n",
      "Epoch [6/10], Batch [450], Loss: 0.014102187938988209\n",
      "Epoch [6/10], Batch [460], Loss: 0.009874291718006134\n",
      "Epoch [6/10], Batch [470], Loss: 0.01209039893001318\n",
      "Epoch [6/10], Batch [480], Loss: 0.006162870209664106\n",
      "Epoch [6/10], Batch [490], Loss: 0.01366080529987812\n",
      "Epoch [6/10], Batch [500], Loss: 0.01141133438795805\n",
      "Epoch [6/10], Batch [510], Loss: 0.008986299857497215\n",
      "Epoch [6/10], Batch [520], Loss: 0.008467361330986023\n",
      "Epoch [6/10], Batch [530], Loss: 0.022513220086693764\n",
      "Epoch [6/10], Batch [540], Loss: 0.016391998156905174\n",
      "Epoch [6/10], Batch [550], Loss: 0.008761837147176266\n",
      "Epoch [6/10], Average Loss: 0.018686482967742172\n",
      "Epoch [7/10], Batch [0], Loss: 0.017972851172089577\n",
      "Epoch [7/10], Batch [10], Loss: 0.021553395316004753\n",
      "Epoch [7/10], Batch [20], Loss: 0.007733384147286415\n",
      "Epoch [7/10], Batch [30], Loss: 0.006076327990740538\n",
      "Epoch [7/10], Batch [40], Loss: 0.004974189680069685\n",
      "Epoch [7/10], Batch [50], Loss: 0.010717170313000679\n",
      "Epoch [7/10], Batch [60], Loss: 0.005687053315341473\n",
      "Epoch [7/10], Batch [70], Loss: 0.014362639747560024\n",
      "Epoch [7/10], Batch [80], Loss: 0.04310178384184837\n",
      "Epoch [7/10], Batch [90], Loss: 0.010876779444515705\n",
      "Epoch [7/10], Batch [100], Loss: 0.010857914574444294\n",
      "Epoch [7/10], Batch [110], Loss: 0.020481674000620842\n",
      "Epoch [7/10], Batch [120], Loss: 0.004706014879047871\n",
      "Epoch [7/10], Batch [130], Loss: 0.006738659460097551\n",
      "Epoch [7/10], Batch [140], Loss: 0.012446933425962925\n",
      "Epoch [7/10], Batch [150], Loss: 0.035793304443359375\n",
      "Epoch [7/10], Batch [160], Loss: 0.020472979173064232\n",
      "Epoch [7/10], Batch [170], Loss: 0.017102055251598358\n",
      "Epoch [7/10], Batch [180], Loss: 0.01860119216144085\n",
      "Epoch [7/10], Batch [190], Loss: 0.022292962297797203\n",
      "Epoch [7/10], Batch [200], Loss: 0.023153379559516907\n",
      "Epoch [7/10], Batch [210], Loss: 0.017679747194051743\n",
      "Epoch [7/10], Batch [220], Loss: 0.009494690224528313\n",
      "Epoch [7/10], Batch [230], Loss: 0.009082301519811153\n",
      "Epoch [7/10], Batch [240], Loss: 0.004475079011172056\n",
      "Epoch [7/10], Batch [250], Loss: 0.006309754215180874\n",
      "Epoch [7/10], Batch [260], Loss: 0.03707442805171013\n",
      "Epoch [7/10], Batch [270], Loss: 0.010668111965060234\n",
      "Epoch [7/10], Batch [280], Loss: 0.014376962557435036\n",
      "Epoch [7/10], Batch [290], Loss: 0.023364892229437828\n",
      "Epoch [7/10], Batch [300], Loss: 0.011052824556827545\n",
      "Epoch [7/10], Batch [310], Loss: 0.011852485127747059\n",
      "Epoch [7/10], Batch [320], Loss: 0.019687307998538017\n",
      "Epoch [7/10], Batch [330], Loss: 0.01408003643155098\n",
      "Epoch [7/10], Batch [340], Loss: 0.0130396019667387\n",
      "Epoch [7/10], Batch [350], Loss: 0.013148265890777111\n",
      "Epoch [7/10], Batch [360], Loss: 0.018908541649580002\n",
      "Epoch [7/10], Batch [370], Loss: 0.005480614490807056\n",
      "Epoch [7/10], Batch [380], Loss: 0.03716094419360161\n",
      "Epoch [7/10], Batch [390], Loss: 0.031995564699172974\n",
      "Epoch [7/10], Batch [400], Loss: 0.012467567808926105\n",
      "Epoch [7/10], Batch [410], Loss: 0.009442517533898354\n",
      "Epoch [7/10], Batch [420], Loss: 0.015465985052287579\n",
      "Epoch [7/10], Batch [430], Loss: 0.005889030639082193\n",
      "Epoch [7/10], Batch [440], Loss: 0.014621969312429428\n",
      "Epoch [7/10], Batch [450], Loss: 0.012893358245491982\n",
      "Epoch [7/10], Batch [460], Loss: 0.009782295674085617\n",
      "Epoch [7/10], Batch [470], Loss: 0.011835549026727676\n",
      "Epoch [7/10], Batch [480], Loss: 0.006073715165257454\n",
      "Epoch [7/10], Batch [490], Loss: 0.013637399300932884\n",
      "Epoch [7/10], Batch [500], Loss: 0.011542498134076595\n",
      "Epoch [7/10], Batch [510], Loss: 0.008492984808981419\n",
      "Epoch [7/10], Batch [520], Loss: 0.008118262514472008\n",
      "Epoch [7/10], Batch [530], Loss: 0.022539149969816208\n",
      "Epoch [7/10], Batch [540], Loss: 0.0162868220359087\n",
      "Epoch [7/10], Batch [550], Loss: 0.008119339123368263\n",
      "Epoch [7/10], Average Loss: 0.01820600283737409\n",
      "Epoch [8/10], Batch [0], Loss: 0.01705106347799301\n",
      "Epoch [8/10], Batch [10], Loss: 0.01626058854162693\n",
      "Epoch [8/10], Batch [20], Loss: 0.006826300639659166\n",
      "Epoch [8/10], Batch [30], Loss: 0.005530994851142168\n",
      "Epoch [8/10], Batch [40], Loss: 0.004656674340367317\n",
      "Epoch [8/10], Batch [50], Loss: 0.011383314616978168\n",
      "Epoch [8/10], Batch [60], Loss: 0.005096448119729757\n",
      "Epoch [8/10], Batch [70], Loss: 0.013931195251643658\n",
      "Epoch [8/10], Batch [80], Loss: 0.04286348074674606\n",
      "Epoch [8/10], Batch [90], Loss: 0.010734627023339272\n",
      "Epoch [8/10], Batch [100], Loss: 0.012034430168569088\n",
      "Epoch [8/10], Batch [110], Loss: 0.02189117856323719\n",
      "Epoch [8/10], Batch [120], Loss: 0.0036977045238018036\n",
      "Epoch [8/10], Batch [130], Loss: 0.006915703881531954\n",
      "Epoch [8/10], Batch [140], Loss: 0.012446093373000622\n",
      "Epoch [8/10], Batch [150], Loss: 0.03501652553677559\n",
      "Epoch [8/10], Batch [160], Loss: 0.019682325422763824\n",
      "Epoch [8/10], Batch [170], Loss: 0.016992468386888504\n",
      "Epoch [8/10], Batch [180], Loss: 0.018387990072369576\n",
      "Epoch [8/10], Batch [190], Loss: 0.022243184968829155\n",
      "Epoch [8/10], Batch [200], Loss: 0.023068878799676895\n",
      "Epoch [8/10], Batch [210], Loss: 0.017652733251452446\n",
      "Epoch [8/10], Batch [220], Loss: 0.00945576187223196\n",
      "Epoch [8/10], Batch [230], Loss: 0.009090353734791279\n",
      "Epoch [8/10], Batch [240], Loss: 0.004352927207946777\n",
      "Epoch [8/10], Batch [250], Loss: 0.00627707177773118\n",
      "Epoch [8/10], Batch [260], Loss: 0.03710603341460228\n",
      "Epoch [8/10], Batch [270], Loss: 0.011557991616427898\n",
      "Epoch [8/10], Batch [280], Loss: 0.014341166242957115\n",
      "Epoch [8/10], Batch [290], Loss: 0.022941138595342636\n",
      "Epoch [8/10], Batch [300], Loss: 0.00781015120446682\n",
      "Epoch [8/10], Batch [310], Loss: 0.007929837331175804\n",
      "Epoch [8/10], Batch [320], Loss: 0.014876965433359146\n",
      "Epoch [8/10], Batch [330], Loss: 0.016612833365797997\n",
      "Epoch [8/10], Batch [340], Loss: 0.013085642829537392\n",
      "Epoch [8/10], Batch [350], Loss: 0.013039288111031055\n",
      "Epoch [8/10], Batch [360], Loss: 0.019346876069903374\n",
      "Epoch [8/10], Batch [370], Loss: 0.005632804241031408\n",
      "Epoch [8/10], Batch [380], Loss: 0.037323713302612305\n",
      "Epoch [8/10], Batch [390], Loss: 0.031734026968479156\n",
      "Epoch [8/10], Batch [400], Loss: 0.012050637044012547\n",
      "Epoch [8/10], Batch [410], Loss: 0.009676074609160423\n",
      "Epoch [8/10], Batch [420], Loss: 0.014590032398700714\n",
      "Epoch [8/10], Batch [430], Loss: 0.005459400359541178\n",
      "Epoch [8/10], Batch [440], Loss: 0.01493379008024931\n",
      "Epoch [8/10], Batch [450], Loss: 0.012356003746390343\n",
      "Epoch [8/10], Batch [460], Loss: 0.00886894017457962\n",
      "Epoch [8/10], Batch [470], Loss: 0.011893144808709621\n",
      "Epoch [8/10], Batch [480], Loss: 0.005980037618428469\n",
      "Epoch [8/10], Batch [490], Loss: 0.013882257975637913\n",
      "Epoch [8/10], Batch [500], Loss: 0.010988341644406319\n",
      "Epoch [8/10], Batch [510], Loss: 0.008234197273850441\n",
      "Epoch [8/10], Batch [520], Loss: 0.007333636283874512\n",
      "Epoch [8/10], Batch [530], Loss: 0.021880559623241425\n",
      "Epoch [8/10], Batch [540], Loss: 0.015966150909662247\n",
      "Epoch [8/10], Batch [550], Loss: 0.00792159978300333\n",
      "Epoch [8/10], Average Loss: 0.01773228129695984\n",
      "Epoch [9/10], Batch [0], Loss: 0.020005911588668823\n",
      "Epoch [9/10], Batch [10], Loss: 0.016259463503956795\n",
      "Epoch [9/10], Batch [20], Loss: 0.0057673705741763115\n",
      "Epoch [9/10], Batch [30], Loss: 0.00491161597892642\n",
      "Epoch [9/10], Batch [40], Loss: 0.005142678041011095\n",
      "Epoch [9/10], Batch [50], Loss: 0.011141398921608925\n",
      "Epoch [9/10], Batch [60], Loss: 0.004648151807487011\n",
      "Epoch [9/10], Batch [70], Loss: 0.013930757530033588\n",
      "Epoch [9/10], Batch [80], Loss: 0.04334022477269173\n",
      "Epoch [9/10], Batch [90], Loss: 0.011572476476430893\n",
      "Epoch [9/10], Batch [100], Loss: 0.007599778939038515\n",
      "Epoch [9/10], Batch [110], Loss: 0.018547505140304565\n",
      "Epoch [9/10], Batch [120], Loss: 0.0024046890903264284\n",
      "Epoch [9/10], Batch [130], Loss: 0.006910845637321472\n",
      "Epoch [9/10], Batch [140], Loss: 0.012497130781412125\n",
      "Epoch [9/10], Batch [150], Loss: 0.031852543354034424\n",
      "Epoch [9/10], Batch [160], Loss: 0.020639702677726746\n",
      "Epoch [9/10], Batch [170], Loss: 0.017095206305384636\n",
      "Epoch [9/10], Batch [180], Loss: 0.01797119714319706\n",
      "Epoch [9/10], Batch [190], Loss: 0.022899525240063667\n",
      "Epoch [9/10], Batch [200], Loss: 0.023039087653160095\n",
      "Epoch [9/10], Batch [210], Loss: 0.017653079703450203\n",
      "Epoch [9/10], Batch [220], Loss: 0.00944251473993063\n",
      "Epoch [9/10], Batch [230], Loss: 0.009023025631904602\n",
      "Epoch [9/10], Batch [240], Loss: 0.0041317809373140335\n",
      "Epoch [9/10], Batch [250], Loss: 0.0064833094365894794\n",
      "Epoch [9/10], Batch [260], Loss: 0.03670365363359451\n",
      "Epoch [9/10], Batch [270], Loss: 0.01074754074215889\n",
      "Epoch [9/10], Batch [280], Loss: 0.014595991000533104\n",
      "Epoch [9/10], Batch [290], Loss: 0.024493994191288948\n",
      "Epoch [9/10], Batch [300], Loss: 0.007068905979394913\n",
      "Epoch [9/10], Batch [310], Loss: 0.006949339061975479\n",
      "Epoch [9/10], Batch [320], Loss: 0.013405938632786274\n",
      "Epoch [9/10], Batch [330], Loss: 0.01451876200735569\n",
      "Epoch [9/10], Batch [340], Loss: 0.013700898736715317\n",
      "Epoch [9/10], Batch [350], Loss: 0.013402107171714306\n",
      "Epoch [9/10], Batch [360], Loss: 0.018956633284687996\n",
      "Epoch [9/10], Batch [370], Loss: 0.005113489460200071\n",
      "Epoch [9/10], Batch [380], Loss: 0.036926738917827606\n",
      "Epoch [9/10], Batch [390], Loss: 0.03148790821433067\n",
      "Epoch [9/10], Batch [400], Loss: 0.012003889307379723\n",
      "Epoch [9/10], Batch [410], Loss: 0.009023929946124554\n",
      "Epoch [9/10], Batch [420], Loss: 0.01408080942928791\n",
      "Epoch [9/10], Batch [430], Loss: 0.0052421195432543755\n",
      "Epoch [9/10], Batch [440], Loss: 0.014951923862099648\n",
      "Epoch [9/10], Batch [450], Loss: 0.012189890258014202\n",
      "Epoch [9/10], Batch [460], Loss: 0.007929649204015732\n",
      "Epoch [9/10], Batch [470], Loss: 0.011474656872451305\n",
      "Epoch [9/10], Batch [480], Loss: 0.006468967534601688\n",
      "Epoch [9/10], Batch [490], Loss: 0.014667975716292858\n",
      "Epoch [9/10], Batch [500], Loss: 0.011098377406597137\n",
      "Epoch [9/10], Batch [510], Loss: 0.00798532273620367\n",
      "Epoch [9/10], Batch [520], Loss: 0.006817371118813753\n",
      "Epoch [9/10], Batch [530], Loss: 0.02180255949497223\n",
      "Epoch [9/10], Batch [540], Loss: 0.015703922137618065\n",
      "Epoch [9/10], Batch [550], Loss: 0.007192882243543863\n",
      "Epoch [9/10], Average Loss: 0.01742566836074878\n",
      "Epoch [10/10], Batch [0], Loss: 0.014844201505184174\n",
      "Epoch [10/10], Batch [10], Loss: 0.015015071257948875\n",
      "Epoch [10/10], Batch [20], Loss: 0.005494518205523491\n",
      "Epoch [10/10], Batch [30], Loss: 0.0049207331612706184\n",
      "Epoch [10/10], Batch [40], Loss: 0.003678341628983617\n",
      "Epoch [10/10], Batch [50], Loss: 0.012556021101772785\n",
      "Epoch [10/10], Batch [60], Loss: 0.004727990832179785\n",
      "Epoch [10/10], Batch [70], Loss: 0.013796874321997166\n",
      "Epoch [10/10], Batch [80], Loss: 0.04262128099799156\n",
      "Epoch [10/10], Batch [90], Loss: 0.011352869682013988\n",
      "Epoch [10/10], Batch [100], Loss: 0.006947370711714029\n",
      "Epoch [10/10], Batch [110], Loss: 0.018402129411697388\n",
      "Epoch [10/10], Batch [120], Loss: 0.0027098560240119696\n",
      "Epoch [10/10], Batch [130], Loss: 0.007122214883565903\n",
      "Epoch [10/10], Batch [140], Loss: 0.012551350519061089\n",
      "Epoch [10/10], Batch [150], Loss: 0.030102653428912163\n",
      "Epoch [10/10], Batch [160], Loss: 0.019909430295228958\n",
      "Epoch [10/10], Batch [170], Loss: 0.01680329069495201\n",
      "Epoch [10/10], Batch [180], Loss: 0.017960531637072563\n",
      "Epoch [10/10], Batch [190], Loss: 0.023000573739409447\n",
      "Epoch [10/10], Batch [200], Loss: 0.022967901080846786\n",
      "Epoch [10/10], Batch [210], Loss: 0.017608722671866417\n",
      "Epoch [10/10], Batch [220], Loss: 0.00949024222791195\n",
      "Epoch [10/10], Batch [230], Loss: 0.00907814409583807\n",
      "Epoch [10/10], Batch [240], Loss: 0.004240717738866806\n",
      "Epoch [10/10], Batch [250], Loss: 0.006266068667173386\n",
      "Epoch [10/10], Batch [260], Loss: 0.03688216954469681\n",
      "Epoch [10/10], Batch [270], Loss: 0.008691239170730114\n",
      "Epoch [10/10], Batch [280], Loss: 0.013719859533011913\n",
      "Epoch [10/10], Batch [290], Loss: 0.022642677649855614\n",
      "Epoch [10/10], Batch [300], Loss: 0.006208657752722502\n",
      "Epoch [10/10], Batch [310], Loss: 0.008315298706293106\n",
      "Epoch [10/10], Batch [320], Loss: 0.01108292955905199\n",
      "Epoch [10/10], Batch [330], Loss: 0.013805241324007511\n",
      "Epoch [10/10], Batch [340], Loss: 0.01331463921815157\n",
      "Epoch [10/10], Batch [350], Loss: 0.013205030001699924\n",
      "Epoch [10/10], Batch [360], Loss: 0.018899165093898773\n",
      "Epoch [10/10], Batch [370], Loss: 0.005098200403153896\n",
      "Epoch [10/10], Batch [380], Loss: 0.036714933812618256\n",
      "Epoch [10/10], Batch [390], Loss: 0.030982814729213715\n",
      "Epoch [10/10], Batch [400], Loss: 0.011841638945043087\n",
      "Epoch [10/10], Batch [410], Loss: 0.008844506926834583\n",
      "Epoch [10/10], Batch [420], Loss: 0.012870961800217628\n",
      "Epoch [10/10], Batch [430], Loss: 0.0053153145126998425\n",
      "Epoch [10/10], Batch [440], Loss: 0.015038218349218369\n",
      "Epoch [10/10], Batch [450], Loss: 0.012776928953826427\n",
      "Epoch [10/10], Batch [460], Loss: 0.007437337655574083\n",
      "Epoch [10/10], Batch [470], Loss: 0.010959159582853317\n",
      "Epoch [10/10], Batch [480], Loss: 0.006156741641461849\n",
      "Epoch [10/10], Batch [490], Loss: 0.014804361388087273\n",
      "Epoch [10/10], Batch [500], Loss: 0.01084454357624054\n",
      "Epoch [10/10], Batch [510], Loss: 0.007912348955869675\n",
      "Epoch [10/10], Batch [520], Loss: 0.006048937793821096\n",
      "Epoch [10/10], Batch [530], Loss: 0.02065296284854412\n",
      "Epoch [10/10], Batch [540], Loss: 0.015576759353280067\n",
      "Epoch [10/10], Batch [550], Loss: 0.00724688358604908\n",
      "Epoch [10/10], Average Loss: 0.016894949011512984\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "from model import NETWORK  # Ensure that model.py is saved in the same directory\n",
    "from dataloaders import * # Ensure that dataloaders.py is saved in the same directory\n",
    "from utils import *\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "\n",
    "# Setup configuration\n",
    "latent_dim = 64  # Latent dimension size, can be adjusted\n",
    "hidden_dim = 512  # Hidden dimension size for the encoder and decoder\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "n_components = 100\n",
    "n_knn_search = 10\n",
    "dataset_name = \"gastrulation_erythroid\"\n",
    "cell_type_key = \"celltype\"\n",
    "model_name = \"imVelo\"\n",
    "\n",
    "num_genes = 2000\n",
    "nhead = 1 #original: 1\n",
    "embedding_dim = 128*nhead# original: 128\n",
    "num_encoder_layers = 1 #original: 1\n",
    "num_bins = 50\n",
    "batch_size = 24  # Batch size for training\n",
    "epochs = 10 # Number of epochs for training\n",
    "learning_rate = 1e-4  # Learning rate for the optimizer\n",
    "lambda1 = 1e-1  # Weight for heuristic loss\n",
    "lambda2 = 1 # Weight for discrepancy loss\n",
    "K = 11  # Number of neighbors for heuristic loss\n",
    "\n",
    "# Load data\n",
    "adata = sc.read_h5ad(\"erythroid_pancreas.h5ad\")\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = NETWORK(input_dim=adata.shape[1]*2, latent_dim=latent_dim, \n",
    "                hidden_dim=hidden_dim, emb_dim = embedding_dim,\n",
    "                nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
    "                num_genes=adata.shape[1], num_bins=num_bins).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Set up data loaders\n",
    "train_loader, test_loader, full_data_loader = setup_dataloaders_binning(adata, \n",
    "                                                                       batch_size=batch_size, \n",
    "                                                                       num_genes=num_genes,\n",
    "                                                                       num_bins=num_bins)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (tokens, data, batch_indices) in enumerate(full_data_loader):\n",
    "        tokens = tokens.to(device)\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \"\"\"print(tokens.shape)\n",
    "        print(data.shape)\n",
    "        print(batch_indices.shape)\"\"\"\n",
    "        \n",
    "        # Forward pass\n",
    "        out_dic = model(tokens, data)\n",
    "        \n",
    "        # Compute loss\n",
    "        losses_dic = model.heuristic_loss(\n",
    "            adata=adata, \n",
    "            x=data, \n",
    "            batch_indices=batch_indices,\n",
    "            lambda1=lambda1, \n",
    "            lambda2=lambda2, \n",
    "            out_dic=out_dic, \n",
    "            device=device,\n",
    "            K=K\n",
    "        )\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss = losses_dic[\"total_loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss for monitoring\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:  # Print every 10 batches\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}], Loss: {loss.item()}')\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "    # Save the model periodically\n",
    "    \"\"\"if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\"\"\"\n",
    "\n",
    "# After training, save final model\n",
    "torch.save(model.state_dict(), 'model_minmax.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepTrajectory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
